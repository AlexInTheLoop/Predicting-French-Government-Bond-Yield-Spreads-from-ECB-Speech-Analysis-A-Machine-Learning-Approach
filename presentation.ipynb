{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117fb69c",
   "metadata": {},
   "source": [
    "### Packages Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.DataManager import DataManager\n",
    "from Models.utils import compare_models_metrics\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from Data.TextVectoriser import TextVectorizer\n",
    "from Models.utils import compare_models_metrics, set_seed\n",
    "\n",
    "from Models.sk_models import (\n",
    "    LogReg, RandomForest,\n",
    "    XGBoostClassifier, KNNClassifier, \n",
    "    NaiveBayesClassifier, LightGBMClassifier,\n",
    "    ExtraTreesClassifierWrapper, AdaBoostClassifierWrapper,\n",
    "    RidgeClassifierWrapper, SGDClassifierWrapper\n",
    ")\n",
    "\n",
    "from Models.torch_mlp import MLPClassifier\n",
    "from Models.torch_hf_transformer import HFTransformerClassifier\n",
    "from Models.utils import batch_check_naive_predictions\n",
    "from Models.utils import compare_models_metrics, set_seed, generalized_gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ea8ab",
   "metadata": {},
   "source": [
    "### Features and Target variable management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de91f6f",
   "metadata": {},
   "source": [
    "This block handles the core data preprocessing pipeline that combines ECB speech data with French government bond yield information to create our modeling dataset.\n",
    "\n",
    "- **ECB Speeches**: Complete textual content of European Central Bank communications from 2011 onwards\n",
    "- **Bond Yield Data**: Daily French government bond spreads between different maturities (2Y, 10Y)\n",
    "\n",
    "The `DataManager` class performs several key operations:\n",
    "\n",
    "1. **Data Loading**: Loads both speech texts and corresponding yield curve data, ensuring proper date parsing and temporal alignment\n",
    "\n",
    "2. **Target Variable Construction**: For each speech date, calculates the directional movement of yield spreads by comparing:\n",
    "  - **Target 1**: 2Y-10Y spread movement (short-term vs medium-term rates)\n",
    "\n",
    "3. **Classification Labels**: Converts continuous spread changes into directional classes:\n",
    "  - `+1`: Spread widening (positive movement)\n",
    "  - `0`: No significant movement\n",
    "  - `-1`: Spread tightening (negative movement)\n",
    "\n",
    "4. **Dataset Export**: Creates a clean, analysis-ready dataset with speech features aligned to their corresponding market impact labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e79b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset exported to c:\\Users\\rabhi\\Documents\\Master 272 IEF - Dauphine\\M2\\S2\\NLP\\projet\\Data\\dataset.csv (1651 rows).\n",
      "Summary of classes (target_1):\n",
      "target_1\n",
      "-1    847\n",
      " 1    795\n",
      " 0      9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary of classes (target_2):\n",
      "target_2\n",
      " 1    856\n",
      "-1    776\n",
      " 0     19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd() \n",
    "manager = DataManager(\n",
    "    speeches_csv=BASE_DIR / \"Data/all_ECB_speeches.csv\",\n",
    "    rates_csv=BASE_DIR / \"Data/data.csv\",\n",
    "    output_csv=BASE_DIR / \"Data/dataset.csv\",\n",
    "    start_date=\"2011-01-01\",\n",
    "    force_binary=False\n",
    ")\n",
    "\n",
    "manager.load_speeches()\n",
    "manager.load_rates()\n",
    "manager.build_dataset()\n",
    "manager.export_dataset()\n",
    "manager.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759e259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8679e9",
   "metadata": {},
   "source": [
    "### Models application with Raw Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1f1d2",
   "metadata": {},
   "source": [
    "This section implements our comprehensive machine learning pipeline to predict yield spread movements from ECB speech content using **raw TF-IDF features** without dimensionality reduction.\n",
    "\n",
    "- **Feature Extraction**: TF-IDF vectorization with up to 50,000 features using unigrams and bigrams\n",
    "- **Temporal Split**: Training on pre-2022 data, testing on 2022+ to simulate realistic deployment conditions\n",
    "- **Feature Space**: Full high-dimensional representation preserving all textual information\n",
    "\n",
    "Automated hyperparameter optimization using `generalized_gridsearch` across multiple algorithm families:\n",
    "- **Linear Models**: Logistic Regression, Ridge, SGD\n",
    "- **Tree-Based Ensembles**: Random Forest, XGBoost, LightGBM, Extra Trees, AdaBoost  \n",
    "- **Instance-Based**: K-Nearest Neighbors\n",
    "- **Probabilistic**: Naive Bayes (Multinomial)\n",
    "\n",
    "Each model undergoes systematic grid search to identify optimal hyperparameters, ensuring fair performance comparison across different algorithmic approaches on the original feature space.\n",
    "\n",
    "Final comparison using F1-macro score to balance performance across all directional movement classes, establishing baseline performance before applying dimensionality reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c03b6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes_Multi</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>0.555526</td>\n",
       "      <td>0.556806</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>[[104, 91], [73, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>[[102, 93], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>[[100, 95], [71, 103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Cosine</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Euclidean</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>0.547412</td>\n",
       "      <td>0.549581</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>[[100, 95], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.544717</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>[[117, 78], [89, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.537887</td>\n",
       "      <td>0.537096</td>\n",
       "      <td>0.538622</td>\n",
       "      <td>0.537887</td>\n",
       "      <td>[[119, 76], [93, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>0.533439</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>[[125, 70], [99, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.531521</td>\n",
       "      <td>0.529901</td>\n",
       "      <td>0.532490</td>\n",
       "      <td>0.531521</td>\n",
       "      <td>[[121, 74], [97, 77]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  balanced_accuracy  f1_macro  precision_macro  \\\n",
       "model                                                                        \n",
       "NaiveBayes_Multi    0.555556           0.556897  0.555526         0.556806   \n",
       "Ridge               0.552846           0.554642  0.552846         0.554642   \n",
       "XGBoost             0.550136           0.552387  0.550106         0.552499   \n",
       "KNN_Cosine          0.550136           0.553006  0.549974         0.553314   \n",
       "KNN_Euclidean       0.550136           0.553006  0.549974         0.553314   \n",
       "LogisticRegression  0.547425           0.549514  0.547412         0.549581   \n",
       "ExtraTrees          0.547425           0.544253  0.543996         0.544717   \n",
       "MLP                 0.542005           0.537887  0.537096         0.538622   \n",
       "AdaBoost            0.542005           0.536030  0.533439         0.537639   \n",
       "RandomForest        0.536585           0.531521  0.529901         0.532490   \n",
       "\n",
       "                    recall_macro        confusion_matrix  \n",
       "model                                                     \n",
       "NaiveBayes_Multi        0.556897  [[104, 91], [73, 101]]  \n",
       "Ridge                   0.554642  [[102, 93], [72, 102]]  \n",
       "XGBoost                 0.552387  [[100, 95], [71, 103]]  \n",
       "KNN_Cosine              0.553006   [[98, 97], [69, 105]]  \n",
       "KNN_Euclidean           0.553006   [[98, 97], [69, 105]]  \n",
       "LogisticRegression      0.549514  [[100, 95], [72, 102]]  \n",
       "ExtraTrees              0.544253   [[117, 78], [89, 85]]  \n",
       "MLP                     0.537887   [[119, 76], [93, 81]]  \n",
       "AdaBoost                0.536030   [[125, 70], [99, 75]]  \n",
       "RandomForest            0.531521   [[121, 74], [97, 77]]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TextVectorizer(\n",
    "    dataset_csv=\"dataset.csv\",\n",
    "    text_cols=(\"speakers\", \"title\", \"subtitle\", \"contents\"),\n",
    "    target_cols=(\"target_1\"),\n",
    "    id_col=\"date\",\n",
    "    concat_text=False\n",
    ")\n",
    "tv.load()\n",
    "\n",
    "X, y, vectorizer = tv.tfidf(target=\"target_1\", max_features=50000, ngram_range=(1, 2))\n",
    "X_tr, X_te, y_tr, y_te = tv.temporal_split(X, y, split_date=\"2022-01-01\")\n",
    "\n",
    "optimized_models = {}\n",
    "\n",
    "result = generalized_gridsearch(LogReg(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LogisticRegression\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RandomForest(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"RandomForest\"] = result['best_model']\n",
    "\n",
    "\n",
    "result = generalized_gridsearch(XGBoostClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"XGBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Cosine\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Euclidean\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(NaiveBayesClassifier(variant=\"multinomial\"), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"NaiveBayes_Multi\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(LightGBMClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LightGBM\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(ExtraTreesClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"ExtraTrees\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(AdaBoostClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"AdaBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RidgeClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"Ridge\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(SGDClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"SGD\"] = result['best_model']\n",
    "\n",
    "input_dim = X_tr.shape[1]\n",
    "mlp = MLPClassifier(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=len(np.unique(y)),\n",
    "    hidden_dims=(512, 128),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    verbose=False\n",
    ")\n",
    "mlp.fit(X_tr, y_tr, X_val=X_te, y_val=y_te)\n",
    "optimized_models[\"MLP\"] = mlp\n",
    "\n",
    "df_metrics = compare_models_metrics(optimized_models, X_te, y_te, average=\"macro\")\n",
    "df_sorted = df_metrics.sort_values('f1_macro', ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1496e0",
   "metadata": {},
   "source": [
    "The following block alidates that all trained models demonstrate genuine learning by checking for naive prediction patterns (e.g., always predicting majority class) and confirming meaningful improvement over dummy classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d226d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_classes_predicted</th>\n",
       "      <th>majority_prediction_ratio</th>\n",
       "      <th>improvement_over_dummy</th>\n",
       "      <th>is_naive_majority</th>\n",
       "      <th>is_single_class_predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590786</td>\n",
       "      <td>0.184157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_Cosine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Euclidean</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes_Multi</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558266</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.187694</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.207101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574526</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  unique_classes_predicted  majority_prediction_ratio  \\\n",
       "0  LogisticRegression                         2                   0.466125   \n",
       "1        RandomForest                         2                   0.590786   \n",
       "2             XGBoost                         2                   0.463415   \n",
       "3          KNN_Cosine                         2                   0.452575   \n",
       "4       KNN_Euclidean                         2                   0.452575   \n",
       "5    NaiveBayes_Multi                         2                   0.479675   \n",
       "6          ExtraTrees                         2                   0.558266   \n",
       "7            AdaBoost                         2                   0.607046   \n",
       "8               Ridge                         2                   0.471545   \n",
       "9                 MLP                         2                   0.574526   \n",
       "\n",
       "   improvement_over_dummy  is_naive_majority  is_single_class_predictor  \n",
       "0                0.201667              False                      False  \n",
       "1                0.184157              False                      False  \n",
       "2                0.204361              False                      False  \n",
       "3                0.204229              False                      False  \n",
       "4                0.204229              False                      False  \n",
       "5                0.209781              False                      False  \n",
       "6                0.198251              False                      False  \n",
       "7                0.187694              False                      False  \n",
       "8                0.207101              False                      False  \n",
       "9                0.191352              False                      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = batch_check_naive_predictions(optimized_models, X_te, y_te, y_tr)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3926ea4",
   "metadata": {},
   "source": [
    "### Models application with reduced Features (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0330",
   "metadata": {},
   "source": [
    "This block repeats the comprehensive model training and hyperparameter optimization pipeline using **PCA-transformed features** to evaluate the impact of linear dimensionality reduction on predictive performance across all algorithm families.RéessayerClaude peut faire des erreurs. Assurez-vous de vérifier ses réponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e29a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.566396</td>\n",
       "      <td>0.568391</td>\n",
       "      <td>0.566392</td>\n",
       "      <td>0.568435</td>\n",
       "      <td>0.568391</td>\n",
       "      <td>[[104, 91], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes_Multi</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>0.555526</td>\n",
       "      <td>0.556806</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>[[104, 91], [73, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>[[102, 93], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>[[100, 95], [71, 103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Cosine</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Euclidean</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>0.547412</td>\n",
       "      <td>0.549581</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>[[100, 95], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.544717</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>[[117, 78], [89, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>0.533439</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>[[125, 70], [99, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.517615</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>0.516333</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>[[105, 90], [88, 86]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  balanced_accuracy  f1_macro  precision_macro  \\\n",
       "model                                                                        \n",
       "MLP                 0.566396           0.568391  0.566392         0.568435   \n",
       "NaiveBayes_Multi    0.555556           0.556897  0.555526         0.556806   \n",
       "Ridge               0.552846           0.554642  0.552846         0.554642   \n",
       "XGBoost             0.550136           0.552387  0.550106         0.552499   \n",
       "KNN_Cosine          0.550136           0.553006  0.549974         0.553314   \n",
       "KNN_Euclidean       0.550136           0.553006  0.549974         0.553314   \n",
       "LogisticRegression  0.547425           0.549514  0.547412         0.549581   \n",
       "ExtraTrees          0.547425           0.544253  0.543996         0.544717   \n",
       "AdaBoost            0.542005           0.536030  0.533439         0.537639   \n",
       "RandomForest        0.517615           0.516357  0.516333         0.516339   \n",
       "\n",
       "                    recall_macro        confusion_matrix  \n",
       "model                                                     \n",
       "MLP                     0.568391  [[104, 91], [69, 105]]  \n",
       "NaiveBayes_Multi        0.556897  [[104, 91], [73, 101]]  \n",
       "Ridge                   0.554642  [[102, 93], [72, 102]]  \n",
       "XGBoost                 0.552387  [[100, 95], [71, 103]]  \n",
       "KNN_Cosine              0.553006   [[98, 97], [69, 105]]  \n",
       "KNN_Euclidean           0.553006   [[98, 97], [69, 105]]  \n",
       "LogisticRegression      0.549514  [[100, 95], [72, 102]]  \n",
       "ExtraTrees              0.544253   [[117, 78], [89, 85]]  \n",
       "AdaBoost                0.536030   [[125, 70], [99, 75]]  \n",
       "RandomForest            0.516357   [[105, 90], [88, 86]]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TextVectorizer(\n",
    "    dataset_csv=\"dataset.csv\",\n",
    "    text_cols=(\"speakers\", \"title\", \"subtitle\", \"contents\"),\n",
    "    target_cols=(\"target_1\"),\n",
    "    id_col=\"date\",\n",
    "    concat_text=False\n",
    ")\n",
    "tv.load()\n",
    "\n",
    "X, y, vectorizer = tv.tfidf(target=\"target_1\", max_features=50000, ngram_range=(1, 2))\n",
    "tv.reduce(X,method=\"pca\")\n",
    "X_tr, X_te, y_tr, y_te = tv.temporal_split(X, y, split_date=\"2022-01-01\")\n",
    "\n",
    "optimized_models = {}\n",
    "\n",
    "result = generalized_gridsearch(LogReg(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LogisticRegression\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RandomForest(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"RandomForest\"] = result['best_model']\n",
    "\n",
    "\n",
    "result = generalized_gridsearch(XGBoostClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"XGBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Cosine\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Euclidean\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(NaiveBayesClassifier(variant=\"multinomial\"), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"NaiveBayes_Multi\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(LightGBMClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LightGBM\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(ExtraTreesClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"ExtraTrees\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(AdaBoostClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"AdaBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RidgeClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"Ridge\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(SGDClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"SGD\"] = result['best_model']\n",
    "\n",
    "input_dim = X_tr.shape[1]\n",
    "mlp = MLPClassifier(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=len(np.unique(y)),\n",
    "    hidden_dims=(512, 128),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    verbose=False\n",
    ")\n",
    "mlp.fit(X_tr, y_tr, X_val=X_te, y_val=y_te)\n",
    "optimized_models[\"MLP\"] = mlp\n",
    "\n",
    "df_metrics = compare_models_metrics(optimized_models, X_te, y_te, average=\"macro\")\n",
    "df_sorted = df_metrics.sort_values('f1_macro', ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798b9089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_classes_predicted</th>\n",
       "      <th>majority_prediction_ratio</th>\n",
       "      <th>improvement_over_dummy</th>\n",
       "      <th>is_naive_majority</th>\n",
       "      <th>is_single_class_predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_Cosine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Euclidean</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes_Multi</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558266</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.187694</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.207101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.468835</td>\n",
       "      <td>0.220648</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  unique_classes_predicted  majority_prediction_ratio  \\\n",
       "0  LogisticRegression                         2                   0.466125   \n",
       "1        RandomForest                         2                   0.523035   \n",
       "2             XGBoost                         2                   0.463415   \n",
       "3          KNN_Cosine                         2                   0.452575   \n",
       "4       KNN_Euclidean                         2                   0.452575   \n",
       "5    NaiveBayes_Multi                         2                   0.479675   \n",
       "6          ExtraTrees                         2                   0.558266   \n",
       "7            AdaBoost                         2                   0.607046   \n",
       "8               Ridge                         2                   0.471545   \n",
       "9                 MLP                         2                   0.468835   \n",
       "\n",
       "   improvement_over_dummy  is_naive_majority  is_single_class_predictor  \n",
       "0                0.201667              False                      False  \n",
       "1                0.170588              False                      False  \n",
       "2                0.204361              False                      False  \n",
       "3                0.204229              False                      False  \n",
       "4                0.204229              False                      False  \n",
       "5                0.209781              False                      False  \n",
       "6                0.198251              False                      False  \n",
       "7                0.187694              False                      False  \n",
       "8                0.207101              False                      False  \n",
       "9                0.220648              False                      False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = batch_check_naive_predictions(optimized_models, X_te, y_te, y_tr)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d0772",
   "metadata": {},
   "source": [
    "### Models application with reduced Features (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06372bb3",
   "metadata": {},
   "source": [
    "Repeats the comprehensive model training and hyperparameter optimization pipeline using **t-SNE-transformed features** to evaluate the impact of non-linear dimensionality reduction on predictive performance across all algorithm families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c00da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes_Multi</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>0.555526</td>\n",
       "      <td>0.556806</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>[[104, 91], [73, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.558266</td>\n",
       "      <td>0.554509</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>0.555391</td>\n",
       "      <td>0.554509</td>\n",
       "      <td>[[121, 74], [89, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>[[102, 93], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>[[100, 95], [71, 103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Cosine</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Euclidean</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>0.547412</td>\n",
       "      <td>0.549581</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>[[100, 95], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.544717</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>[[117, 78], [89, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>0.533439</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>[[125, 70], [99, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.517615</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>0.516333</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>[[105, 90], [88, 86]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  balanced_accuracy  f1_macro  precision_macro  \\\n",
       "model                                                                        \n",
       "NaiveBayes_Multi    0.555556           0.556897  0.555526         0.556806   \n",
       "MLP                 0.558266           0.554509  0.554021         0.555391   \n",
       "Ridge               0.552846           0.554642  0.552846         0.554642   \n",
       "XGBoost             0.550136           0.552387  0.550106         0.552499   \n",
       "KNN_Cosine          0.550136           0.553006  0.549974         0.553314   \n",
       "KNN_Euclidean       0.550136           0.553006  0.549974         0.553314   \n",
       "LogisticRegression  0.547425           0.549514  0.547412         0.549581   \n",
       "ExtraTrees          0.547425           0.544253  0.543996         0.544717   \n",
       "AdaBoost            0.542005           0.536030  0.533439         0.537639   \n",
       "RandomForest        0.517615           0.516357  0.516333         0.516339   \n",
       "\n",
       "                    recall_macro        confusion_matrix  \n",
       "model                                                     \n",
       "NaiveBayes_Multi        0.556897  [[104, 91], [73, 101]]  \n",
       "MLP                     0.554509   [[121, 74], [89, 85]]  \n",
       "Ridge                   0.554642  [[102, 93], [72, 102]]  \n",
       "XGBoost                 0.552387  [[100, 95], [71, 103]]  \n",
       "KNN_Cosine              0.553006   [[98, 97], [69, 105]]  \n",
       "KNN_Euclidean           0.553006   [[98, 97], [69, 105]]  \n",
       "LogisticRegression      0.549514  [[100, 95], [72, 102]]  \n",
       "ExtraTrees              0.544253   [[117, 78], [89, 85]]  \n",
       "AdaBoost                0.536030   [[125, 70], [99, 75]]  \n",
       "RandomForest            0.516357   [[105, 90], [88, 86]]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TextVectorizer(\n",
    "    dataset_csv=\"dataset.csv\",\n",
    "    text_cols=(\"speakers\", \"title\", \"subtitle\", \"contents\"),\n",
    "    target_cols=(\"target_1\"),\n",
    "    id_col=\"date\",\n",
    "    concat_text=False\n",
    ")\n",
    "tv.load()\n",
    "\n",
    "X, y, vectorizer = tv.tfidf(target=\"target_1\", max_features=50000, ngram_range=(1, 2))\n",
    "tv.reduce(X,method=\"tsne\", n_components=3)\n",
    "X_tr, X_te, y_tr, y_te = tv.temporal_split(X, y, split_date=\"2022-01-01\")\n",
    "\n",
    "optimized_models = {}\n",
    "\n",
    "result = generalized_gridsearch(LogReg(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LogisticRegression\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RandomForest(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"RandomForest\"] = result['best_model']\n",
    "\n",
    "\n",
    "result = generalized_gridsearch(XGBoostClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"XGBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Cosine\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Euclidean\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(NaiveBayesClassifier(variant=\"multinomial\"), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"NaiveBayes_Multi\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(LightGBMClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LightGBM\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(ExtraTreesClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"ExtraTrees\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(AdaBoostClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"AdaBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RidgeClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"Ridge\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(SGDClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"SGD\"] = result['best_model']\n",
    "\n",
    "input_dim = X_tr.shape[1]\n",
    "mlp = MLPClassifier(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=len(np.unique(y)),\n",
    "    hidden_dims=(512, 128),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    verbose=False\n",
    ")\n",
    "mlp.fit(X_tr, y_tr, X_val=X_te, y_val=y_te)\n",
    "optimized_models[\"MLP\"] = mlp\n",
    "\n",
    "df_metrics = compare_models_metrics(optimized_models, X_te, y_te, average=\"macro\")\n",
    "df_sorted = df_metrics.sort_values('f1_macro', ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf84035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_classes_predicted</th>\n",
       "      <th>majority_prediction_ratio</th>\n",
       "      <th>improvement_over_dummy</th>\n",
       "      <th>is_naive_majority</th>\n",
       "      <th>is_single_class_predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_Cosine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Euclidean</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes_Multi</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558266</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.187694</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.207101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.208276</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  unique_classes_predicted  majority_prediction_ratio  \\\n",
       "0  LogisticRegression                         2                   0.466125   \n",
       "1        RandomForest                         2                   0.523035   \n",
       "2             XGBoost                         2                   0.463415   \n",
       "3          KNN_Cosine                         2                   0.452575   \n",
       "4       KNN_Euclidean                         2                   0.452575   \n",
       "5    NaiveBayes_Multi                         2                   0.479675   \n",
       "6          ExtraTrees                         2                   0.558266   \n",
       "7            AdaBoost                         2                   0.607046   \n",
       "8               Ridge                         2                   0.471545   \n",
       "9                 MLP                         2                   0.569106   \n",
       "\n",
       "   improvement_over_dummy  is_naive_majority  is_single_class_predictor  \n",
       "0                0.201667              False                      False  \n",
       "1                0.170588              False                      False  \n",
       "2                0.204361              False                      False  \n",
       "3                0.204229              False                      False  \n",
       "4                0.204229              False                      False  \n",
       "5                0.209781              False                      False  \n",
       "6                0.198251              False                      False  \n",
       "7                0.187694              False                      False  \n",
       "8                0.207101              False                      False  \n",
       "9                0.208276              False                      False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = batch_check_naive_predictions(optimized_models, X_te, y_te, y_tr)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c66f7",
   "metadata": {},
   "source": [
    "### Models application with reduced Features (MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cc8a6",
   "metadata": {},
   "source": [
    "Repeats the comprehensive model training and hyperparameter optimization pipeline using **MDS-transformed features** to evaluate the impact of distance-preserving dimensionality reduction on predictive performance across all algorithm families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe25c77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes_Multi</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>0.555526</td>\n",
       "      <td>0.556806</td>\n",
       "      <td>0.556897</td>\n",
       "      <td>[[104, 91], [73, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>[[102, 93], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.552387</td>\n",
       "      <td>[[100, 95], [71, 103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Cosine</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_Euclidean</th>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.549974</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>[[98, 97], [69, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>0.547412</td>\n",
       "      <td>0.549581</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>[[100, 95], [72, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.544717</td>\n",
       "      <td>0.544253</td>\n",
       "      <td>[[117, 78], [89, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.547425</td>\n",
       "      <td>0.554156</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.557005</td>\n",
       "      <td>0.554156</td>\n",
       "      <td>[[85, 110], [57, 117]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.542005</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>0.533439</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>0.536030</td>\n",
       "      <td>[[125, 70], [99, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.517615</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>0.516333</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>0.516357</td>\n",
       "      <td>[[105, 90], [88, 86]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  balanced_accuracy  f1_macro  precision_macro  \\\n",
       "model                                                                        \n",
       "NaiveBayes_Multi    0.555556           0.556897  0.555526         0.556806   \n",
       "Ridge               0.552846           0.554642  0.552846         0.554642   \n",
       "XGBoost             0.550136           0.552387  0.550106         0.552499   \n",
       "KNN_Cosine          0.550136           0.553006  0.549974         0.553314   \n",
       "KNN_Euclidean       0.550136           0.553006  0.549974         0.553314   \n",
       "LogisticRegression  0.547425           0.549514  0.547412         0.549581   \n",
       "ExtraTrees          0.547425           0.544253  0.543996         0.544717   \n",
       "MLP                 0.547425           0.554156  0.543996         0.557005   \n",
       "AdaBoost            0.542005           0.536030  0.533439         0.537639   \n",
       "RandomForest        0.517615           0.516357  0.516333         0.516339   \n",
       "\n",
       "                    recall_macro        confusion_matrix  \n",
       "model                                                     \n",
       "NaiveBayes_Multi        0.556897  [[104, 91], [73, 101]]  \n",
       "Ridge                   0.554642  [[102, 93], [72, 102]]  \n",
       "XGBoost                 0.552387  [[100, 95], [71, 103]]  \n",
       "KNN_Cosine              0.553006   [[98, 97], [69, 105]]  \n",
       "KNN_Euclidean           0.553006   [[98, 97], [69, 105]]  \n",
       "LogisticRegression      0.549514  [[100, 95], [72, 102]]  \n",
       "ExtraTrees              0.544253   [[117, 78], [89, 85]]  \n",
       "MLP                     0.554156  [[85, 110], [57, 117]]  \n",
       "AdaBoost                0.536030   [[125, 70], [99, 75]]  \n",
       "RandomForest            0.516357   [[105, 90], [88, 86]]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TextVectorizer(\n",
    "    dataset_csv=\"dataset.csv\",\n",
    "    text_cols=(\"speakers\", \"title\", \"subtitle\", \"contents\"),\n",
    "    target_cols=(\"target_1\"),\n",
    "    id_col=\"date\",\n",
    "    concat_text=False\n",
    ")\n",
    "tv.load()\n",
    "\n",
    "X, y, vectorizer = tv.tfidf(target=\"target_1\", max_features=50000, ngram_range=(1, 2))\n",
    "tv.reduce(X,method=\"mds\")\n",
    "X_tr, X_te, y_tr, y_te = tv.temporal_split(X, y, split_date=\"2022-01-01\")\n",
    "\n",
    "optimized_models = {}\n",
    "\n",
    "result = generalized_gridsearch(LogReg(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LogisticRegression\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RandomForest(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"RandomForest\"] = result['best_model']\n",
    "\n",
    "\n",
    "result = generalized_gridsearch(XGBoostClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"XGBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Cosine\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(KNNClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"KNN_Euclidean\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(NaiveBayesClassifier(variant=\"multinomial\"), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"NaiveBayes_Multi\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(LightGBMClassifier(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"LightGBM\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(ExtraTreesClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"ExtraTrees\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(AdaBoostClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"AdaBoost\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(RidgeClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"Ridge\"] = result['best_model']\n",
    "\n",
    "result = generalized_gridsearch(SGDClassifierWrapper(), X_tr, y_tr, X_te, y_te, verbose=False)\n",
    "if result['best_model']:\n",
    "    optimized_models[\"SGD\"] = result['best_model']\n",
    "\n",
    "input_dim = X_tr.shape[1]\n",
    "mlp = MLPClassifier(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=len(np.unique(y)),\n",
    "    hidden_dims=(512, 128),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    verbose=False\n",
    ")\n",
    "mlp.fit(X_tr, y_tr, X_val=X_te, y_val=y_te)\n",
    "optimized_models[\"MLP\"] = mlp\n",
    "\n",
    "df_metrics = compare_models_metrics(optimized_models, X_te, y_te, average=\"macro\")\n",
    "df_sorted = df_metrics.sort_values('f1_macro', ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a0c6027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_classes_predicted</th>\n",
       "      <th>majority_prediction_ratio</th>\n",
       "      <th>improvement_over_dummy</th>\n",
       "      <th>is_naive_majority</th>\n",
       "      <th>is_single_class_predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_Cosine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Euclidean</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452575</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes_Multi</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558266</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.187694</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.207101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384824</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  unique_classes_predicted  majority_prediction_ratio  \\\n",
       "0  LogisticRegression                         2                   0.466125   \n",
       "1        RandomForest                         2                   0.523035   \n",
       "2             XGBoost                         2                   0.463415   \n",
       "3          KNN_Cosine                         2                   0.452575   \n",
       "4       KNN_Euclidean                         2                   0.452575   \n",
       "5    NaiveBayes_Multi                         2                   0.479675   \n",
       "6          ExtraTrees                         2                   0.558266   \n",
       "7            AdaBoost                         2                   0.607046   \n",
       "8               Ridge                         2                   0.471545   \n",
       "9                 MLP                         2                   0.384824   \n",
       "\n",
       "   improvement_over_dummy  is_naive_majority  is_single_class_predictor  \n",
       "0                0.201667              False                      False  \n",
       "1                0.170588              False                      False  \n",
       "2                0.204361              False                      False  \n",
       "3                0.204229              False                      False  \n",
       "4                0.204229              False                      False  \n",
       "5                0.209781              False                      False  \n",
       "6                0.198251              False                      False  \n",
       "7                0.187694              False                      False  \n",
       "8                0.207101              False                      False  \n",
       "9                0.198251              False                      False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = batch_check_naive_predictions(optimized_models, X_te, y_te, y_tr)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e6c54",
   "metadata": {},
   "source": [
    "### HFT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2902d",
   "metadata": {},
   "source": [
    "Implements a **Transformer-based approach** using CamemBERT for comparison with traditional machine learning methods. This model processes raw text directly through pre-trained language representations, fine-tuned on our specific yield spread prediction task with early stopping and mixed-precision training for computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decbab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :\n",
      " 0.5284552845528455\n",
      "balanced_accuracy :\n",
      " 0.5\n",
      "f1_macro :\n",
      " 0.34574468085106386\n",
      "precision_macro :\n",
      " 0.26422764227642276\n",
      "recall_macro :\n",
      " 0.5\n",
      "confusion_matrix :\n",
      " [[195   0]\n",
      " [174   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5284552845528455,\n",
       " 'balanced_accuracy': 0.5,\n",
       " 'f1_macro': 0.34574468085106386,\n",
       " 'precision_macro': 0.26422764227642276,\n",
       " 'recall_macro': 0.5,\n",
       " 'confusion_matrix': array([[195,   0],\n",
       "        [174,   0]], dtype=int64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tv.df\n",
    "df[\"text\"] = df[list(tv.text_cols)].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "split_date = \"2022-01-01\"\n",
    "mask_tr = pd.to_datetime(df[\"date\"]) < pd.Timestamp(split_date)\n",
    "mask_te = ~mask_tr\n",
    "\n",
    "X_tr_hf, y_tr_hf = df.loc[mask_tr, \"text\"], y[mask_tr]\n",
    "X_te_hf, y_te_hf = df.loc[mask_te, \"text\"], y[mask_te]\n",
    "\n",
    "hf_model = HFTransformerClassifier(\n",
    "    model_name=\"camembert-base\",\n",
    "    max_length=512,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    lr=2e-5,\n",
    "    fp16=True,\n",
    "    early_stopping_patience=1,\n",
    "    eval_every=1,\n",
    "    auto_remap_labels=True\n",
    ")\n",
    "hf_model.fit(X_tr_hf, y_tr_hf, X_val=X_te_hf, y_val=y_te_hf)\n",
    "hf_model.evaluate(X_te_hf, y_te_hf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
